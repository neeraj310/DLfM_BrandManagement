{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook to train, save, and load a model, which will be used on the Flask Webapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "To predict the presence of perceptual brand attributes in the images that consumers post online. \n",
    "\n",
    "## Multiclass Problem\n",
    "It is a multiclass problem with a brand can be preceived with one of the 4 attributes : Fun, Healthy, Rugged or Glamarous. \n",
    "For current problem, we are follwing transfer learning approach to use pretrained resnet50 model and retrain the final layer \n",
    "with our the training data.\n",
    "For solving multiclass problems, two approaches are used in machine learning\n",
    "\n",
    "### One Vs Rest (One Vs All)\n",
    "Requires n classifiers if n number of classes exist. **Decision rule**:Predict class label with the highest probability. \n",
    "\n",
    "\n",
    "### One Vs One\n",
    "In this we have to train binary classifier for each class pair. \n",
    "**Decision rule**:Score for output a data item towards one class, combines all classifier's probability involving this class in the class pairs. Requires nC2 classfiers if n number of classes exist.\n",
    "\n",
    "For current problem, we are choosing One Vs Rest approach as we want to limit the number of classifiers to number of attributes. Each classifier requires its own dataset, and loading multiple datasets into memory with huge trainign corpus results in memory not avaliable errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "try: \n",
    "  print('set memory growth')\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "except: \n",
    "  # Invalid device or cannot modify virtual devices once initialized. \n",
    "  pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=300\n",
    "IMG_HEIGHT=300\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "We are going to do following data processing steps\n",
    "\n",
    " - Read images in 2 arrays corresponding to positive or negative images\n",
    " - Remove corrupt images\n",
    " - label all the antonym negative on all attributes\n",
    " - Since we already have large amount of training images, we are not going to use any data augmentation technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images in the attribute folders\n",
    "# path to the downloaded flickr images\n",
    "data_dir = 'C://Users//neera//Documents//Python Scripts//2nd_sem//DLS//data_code_submission//data//Flickr//images_train//'\n",
    "# We are looking for 4 positive and 4 negative attiribures for training the model\n",
    "all_attributes = ['glamorous', 'rugged', 'fun', 'healthy']\n",
    "all_antonyms = ['drab', 'gentle', 'unhealthy', 'dull']\n",
    "num_attributes = len(all_attributes)\n",
    "\n",
    "n_images = []\n",
    "history = [[] for i in range(num_attributes)]\n",
    "p_images = [[] for i in range(num_attributes)]\n",
    "pi_array = [[] for i in range(num_attributes)]\n",
    "train_class = [[] for i in range(num_attributes)]\n",
    "y_labels = [[] for i in range(num_attributes)]\n",
    "\n",
    "label = 'negative'\n",
    "for i in range(num_attributes):\n",
    "    antonym_dir = data_dir + all_antonyms[i]\n",
    "    r_images = [antonym_dir + '//' + f for f in os.listdir(antonym_dir)]\n",
    "    j = 0\n",
    "    for r in r_images:\n",
    "        img = cv2.imread(r)\n",
    "        if img is None: # We only keep good images\n",
    "            continue\n",
    "        n_images.append(r)\n",
    "        #all_labels.append(label)\n",
    "        j = j+1\n",
    "        if j > 3:\n",
    "            break\n",
    "        \n",
    "\n",
    "# For each attribute, assign a label to the image. \n",
    "for i in range(num_attributes):\n",
    "    attribute_dir = data_dir + all_attributes[i]\n",
    "    r_images = [attribute_dir + '//' + f for f in os.listdir(attribute_dir)]\n",
    "    \n",
    "    label = all_attributes[i]\n",
    "    j = 0\n",
    "    for r in r_images:\n",
    "        img = cv2.imread(r)\n",
    "        if img is None: # We only keep good images\n",
    "            continue\n",
    "        p_images[i].append(r)\n",
    "        #all_labels.append(label)\n",
    "        j = j+1\n",
    "        if j > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p_image\n",
    "This structure consists of names of all iamges corresponding to positive attributes. We are going to work with images name for data preprocessing, instead of working with image data itself. Since image data is quite a big strucutre, working with just image name,  we can make certain preprocessing functions to execure faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_attributes):\n",
    "    pi_array[i] = np.array(p_images[i])\n",
    "    pi_array[i] =  pi_array[i].reshape(pi_array[i].shape[0],1)\n",
    " \n",
    "ni_array =np.array(n_images)\n",
    "ni_array = ni_array.reshape(ni_array.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating four copies of Training Data\n",
    "\n",
    "Since we are using one vs rest approach of multiclass classification, we need to create 4 classifiers one for each attribute.  We need to create 4 datasets, one for each classifier. \n",
    "\n",
    " - First DataSet will have samples with attribute Glamorous being labeled as 1, and all other images are labeled as negative. \n",
    "\n",
    " - Second DataSet will have samples with attribute Rugged being labeled as 1, and all other images are labeled as negative. \n",
    "\n",
    " - Basically each dataset will have identify one of the class as positive(labeled as 1) and all other images as negative(labeled as 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 copies of training data set each corresponding to one classfier\n",
    "train_class[0] = np.vstack((pi_array[0], pi_array[1],pi_array[2], pi_array[3], ni_array))\n",
    "train_class[1] = np.vstack((pi_array[1], pi_array[0],pi_array[2], pi_array[3], ni_array))\n",
    "train_class[2] = np.vstack((pi_array[2], pi_array[0],pi_array[1], pi_array[3], ni_array))\n",
    "train_class[3] = np.vstack((pi_array[3], pi_array[0],pi_array[1], pi_array[2], ni_array))\n",
    "\n",
    "print(train_class[0].shape)\n",
    "print(train_class[1].shape)\n",
    "print(train_class[2].shape)\n",
    "print(train_class[3].shape)\n",
    "\n",
    "y_labels[0] = np.vstack((np.ones((pi_array[0].shape[0],1)) , \n",
    "                         np.zeros((pi_array[1].shape[0] +pi_array[2].shape[0] + pi_array[3].shape[0] + ni_array.shape[0] ,1))))\n",
    "\n",
    "y_labels[1] = np.vstack((np.ones((pi_array[1].shape[0],1)) , \n",
    "                         np.zeros((pi_array[0].shape[0] +pi_array[2].shape[0] + pi_array[3].shape[0] + ni_array.shape[0] ,1))))\n",
    "\n",
    "y_labels[2] = np.vstack((np.ones((pi_array[2].shape[0],1)) , \n",
    "                         np.zeros((pi_array[0].shape[0] +pi_array[1].shape[0] + pi_array[3].shape[0] + ni_array.shape[0] ,1))))\n",
    "\n",
    "y_labels[3] = np.vstack((np.ones((pi_array[3].shape[0],1)) , \n",
    "                         np.zeros((pi_array[0].shape[0] +pi_array[1].shape[0] + pi_array[2].shape[0] + ni_array.shape[0] ,1))))\n",
    "\n",
    "print(y_labels[0].shape)\n",
    "print(y_labels[1].shape)\n",
    "print(y_labels[2].shape)\n",
    "print(y_labels[3].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split \n",
    " - We split the data set into training,validation and testing data in ration of 80,10 and 10 percent\n",
    " - We are still working with images name instead of image data itself, as working with images names(which is much smaller strucutre than image data) make pre processing much more faster. \n",
    " - Since we are not doing any data augmentation, we can load the actual image after all the data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_split(all_images,all_labels):\n",
    "    \n",
    "    num_images = len(all_images)\n",
    "    shuffled_all_images, shuffled_all_labels, shuffled_id = \\\n",
    "    shuffle(all_images, all_labels, list(range(num_images)), random_state=66)\n",
    "\n",
    "    # As the images/labels are shuffled in the previous stage, they are \n",
    "    # randomly ordered, so we will truncated the data directly into train, val, \n",
    "    # and test\n",
    "\n",
    "    num_images = len(shuffled_all_images)\n",
    "    # number of 10% of all images\n",
    "    num_10_percent = int(num_images * 0.1)\n",
    "    print(num_10_percent)\n",
    "\n",
    "    train_80_images = shuffled_all_images[0:num_10_percent * 8]\n",
    "    train_labels = shuffled_all_labels[0:num_10_percent * 8]\n",
    "\n",
    "    val_10_images = shuffled_all_images[num_10_percent*8:num_10_percent*9]\n",
    "    val_labels = shuffled_all_labels[num_10_percent*8:num_10_percent*9]\n",
    "\n",
    "    test_10_images = shuffled_all_images[num_10_percent*9:]\n",
    "    test_labels = shuffled_all_labels[num_10_percent*9:]\n",
    "\n",
    "    print(len(train_80_images))\n",
    "    print(len(train_labels))\n",
    "    print(len(val_10_images))\n",
    "    print(len(val_labels))\n",
    "    print(len(test_10_images))\n",
    "    print(len(test_labels))\n",
    "    return (train_80_images, train_labels,val_10_images, val_labels,test_10_images,test_labels)\n",
    "\n",
    "X_train = [[] for i in range(num_attributes)]\n",
    "X_val = [[] for i in range(num_attributes)]\n",
    "X_test = [[] for i in range(num_attributes)]\n",
    "y_train = [[] for i in range(num_attributes)]\n",
    "y_val = [[] for i in range(num_attributes)]\n",
    "y_test = [[] for i in range(num_attributes)]\n",
    "for i in range(num_attributes):\n",
    "    print(i)\n",
    "    (X_train[i], y_train[i],X_val[i], y_val[i],X_test[i],y_test[i]) = train_data_split(train_class[i], y_labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Test data for all attributes\n",
    "\n",
    "Test data needs to be common to all the 4 classifiers. For test data, prediction from each classifier will be merged to give one label for each test sample. Suppose for a paricular test image, classifier 1 gives probability(0.1, prediction is that image does not belong to first attribute), classifier 2 gives probability (0.8, prediction is that image does belong to 2nd attribute), and so on. All the four predictions will be merge together to give a label correponding to a classifier with highest probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_0 = np.where(y_test[0] == 1)\n",
    "count_0 =  (y_test[0][index_0]).shape[0]\n",
    "index_1 = np.where(y_test[1] == 1)\n",
    "count_1 =  (y_test[1][index_1]).shape[0]\n",
    "index_2 = np.where(y_test[2] == 1)\n",
    "count_2 =  (y_test[2][index_2]).shape[0]\n",
    "index_3 = np.where(y_test[3] == 1)\n",
    "count_3 =  (y_test[3][index_3]).shape[0]\n",
    "y_test_all = np.vstack((np.zeros((count_0, 1)), np.ones((count_1,1)), 2*np.ones((count_2,1)), 3*np.ones((count_3,1)) ))\n",
    "X_test_all = []\n",
    "for j in index_0[0]:\n",
    "    X_test_all.append(X_test[0][j])\n",
    "for j in index_1[0]:\n",
    "    X_test_all.append(X_test[1][j])\n",
    "for j in index_2[0]:\n",
    "    X_test_all.append(X_test[2][j])\n",
    "for j in index_3[0]:\n",
    "    X_test_all.append(X_test[3][j])\n",
    "X_test_all = np.array(X_test_all)\n",
    "\n",
    "print(y_test_all.shape)\n",
    "print(X_test_all.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save training, validation and test data\n",
    "Since training data is very large, we cannot load all 4 datasets at the same time. GPU memory allows only 1 dataset to be loaded We need to train each classifier independently. So we save the training/validation/test data into numpy arrays, traing each classifier one by one by loading corresponding data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_attributes):\n",
    "    train_images_file = '5000//X_train_' + str(i)\n",
    "    np.save(train_images_file, X_train[i])\n",
    "    train_label_file = '5000//y_train_' + str(i)\n",
    "    np.save(train_label_file, y_train[i])\n",
    "for i in range(num_attributes):\n",
    "    val_images_file = '5000//X_val_' + str(i)\n",
    "    np.save(val_images_file, X_val[i])\n",
    "    val_label_file = '5000//y_val_' + str(i)\n",
    "    np.save(val_label_file, y_val[i])\n",
    "np.save('5000//X_test_all', X_test_all)\n",
    "np.save('5000//y_test_all', y_test_all)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
