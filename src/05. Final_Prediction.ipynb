{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please refer to notebook Train_Validation_Test_Split for more details about problem statement.\n",
    "\n",
    "This notebook expects that user has already run notebook Run_Model 4 times to save 4 models, each corresponding to one attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "try: \n",
    "  print('set memory growth')\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "except: \n",
    "  # Invalid device or cannot modify virtual devices once initialized. \n",
    "  pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=300\n",
    "IMG_HEIGHT=300\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "num_attributes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the earlier save test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all = np.load('5000//X_test_all.npy')\n",
    "y_test_all = np.load('5000//y_test_all.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all= X_test_all.flatten()\n",
    "X_test_all = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in X_test_all.tolist()]\n",
    "X_test_all = np.array(X_test_all)\n",
    "y_test_all = np.array(y_test_all)\n",
    "\n",
    "print( X_test_all.shape)\n",
    "print( y_test_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get true label for each attribute for individual classifier performance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_true = [[] for i in range(num_attributes)]\n",
    "for i in range(num_attributes):\n",
    "    y_true[i] = np.zeros((y_test_all.shape[0],1))\n",
    "    \n",
    "for i in range(num_attributes):\n",
    "    index = np.where(y_test_all == i)\n",
    "    y_true[i][index] = 1\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 4 Models. 1 Model for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes =4\n",
    "model = [[] for i in range(num_attributes)]\n",
    "model[0] = keras.models.load_model('./savemodels_2/glamarous_model.h5')\n",
    "model[1] = keras.models.load_model('./savemodels_2/rugged_model.h5')\n",
    "model[2] = keras.models.load_model('./savemodels_2/fun_model.h5')\n",
    "model[3] = keras.models.load_model('./savemodels_3/healthy_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Since we are using one vs rest approach of multiclass classification, we need to create 4 classifiers one for each attribute. \n",
    "\n",
    "For test data, prediction from each classifier will be merged to give one label for each test sample. Suppose for a paricular test image, classifier 1 gives probability(0.1, prediction is that image does not belong to first attribute), classifier 2 gives probability (0.8, prediction is that image does belong to 2nd attribute), and so on. All the four predictions will be merge together to give a label correponding to a classifier with highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''\n",
    " Take as input probability output of 4 classfiers coressponding to each class( We have 4 classes and \n",
    " one classfier corresponding to each class )\n",
    " Predict the class label which have the highest probability \n",
    " Return the class label corresponding to class which have highest probablity\n",
    "'''\n",
    "def give_ovr_class_label_output(y_pred):\n",
    "    '''\n",
    "    Stack 4 probabilities to get a numpy array \n",
    "    '''\n",
    "    yclass= np.hstack((y_pred[0], y_pred[1],y_pred[2],y_pred[3]))\n",
    "        \n",
    "    y_class = np.array( yclass )\n",
    "    '''\n",
    "    Get the index corresponding to the max value of column\n",
    "    '''\n",
    "    idx = np.argmax(y_class, axis=-1)\n",
    "    y_class = np.zeros(y_class.shape )\n",
    "    '''\n",
    "    Convert the one hot position into class label\n",
    "    '''\n",
    "    y_class[ np.arange(y_class.shape[0]), idx] = 1\n",
    "    y_train_pred = np.argmax(y_class, axis=1)\n",
    "    return y_train_pred\n",
    "\n",
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [[] for i in range(num_attributes)]\n",
    "for i in range(num_attributes):\n",
    "    y_pred[i] = model[i].predict(X_test_all)\n",
    "y_pred_label = give_ovr_class_label_output(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Confusion Matrix')\n",
    "cm = confusion_matrix(y_test_all, \\\n",
    "                      y_pred_label)\n",
    "print(cm)\n",
    "\n",
    "a = accuracy_score(y_test_all,y_pred_label)\n",
    "print('\\nAccuracy is:', a*100)\n",
    "\n",
    "a = f1_score(y_test_all,y_pred_label,average=\"macro\")\n",
    "print('\\nF1 Score is:', a*100)\n",
    "\n",
    "print(\"\\nlabel precision recall\")\n",
    "for label in range(4):\n",
    "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Prediction Accuracy for individual Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_inv = [[] for i in range(num_attributes)]\n",
    "for i in range(num_attributes):\n",
    "    y_pred_inv[i] = ((y_pred[i])> 0.5).astype(int)\n",
    "    print( 'Model Accuracy for Model Number {} is {}'.format(i, (accuracy_score(y_true[i],y_pred_inv[i]) )*100))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
