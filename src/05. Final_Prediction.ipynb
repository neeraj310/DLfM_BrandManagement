{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please refer to notebook Train_Validation_Test_Split for more details about problem statement.\n",
    "\n",
    "This notebook expects that user has already run notebook Run_Model 4 times to save 4 models, each corresponding to one attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set memory growth\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "try: \n",
    "  print('set memory growth')\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "except: \n",
    "  # Invalid device or cannot modify virtual devices once initialized. \n",
    "  pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=300\n",
    "IMG_HEIGHT=300\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the earlier save test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all = np.load('5000//X_test_all.npy')\n",
    "y_test_all = np.load('5000//y_test_all.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 300, 300, 3)\n",
      "(665, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test_all= X_test_all.flatten()\n",
    "X_test_all = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in X_test_all.tolist()]\n",
    "X_test_all = np.array(X_test_all)\n",
    "y_test_all = np.array(y_test_all)\n",
    "\n",
    "print( X_test_all.shape)\n",
    "print( y_test_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 4 Models. 1 Model for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes =4\n",
    "model = [[] for i in range(num_attributes)]\n",
    "model[0] = keras.models.load_model('./savemodels/glamorous_model.h5')\n",
    "model[1] = keras.models.load_model('./savemodels/rugged_model.h5')\n",
    "model[2] = keras.models.load_model('./savemodels/fun_model.h5')\n",
    "model[3] = keras.models.load_model('./savemodels/healthy_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Since we are using one vs rest approach of multiclass classification, we need to create 4 classifiers one for each attribute. \n",
    "\n",
    "For test data, prediction from each classifier will be merged to give one label for each test sample. Suppose for a paricular test image, classifier 1 gives probability(0.1, prediction is that image does not belong to first attribute), classifier 2 gives probability (0.8, prediction is that image does belong to 2nd attribute), and so on. All the four predictions will be merge together to give a label correponding to a classifier with highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''\n",
    " Take as input probability output of 4 classfiers coressponding to each class( We have 4 classes and \n",
    " one classfier corresponding to each class )\n",
    " Predict the class label which have the highest probability \n",
    " Return the class label corresponding to class which have highest probablity\n",
    "'''\n",
    "def give_ovr_class_label_output(y_pred):\n",
    "    '''\n",
    "    Stack 4 probabilities to get a numpy array \n",
    "    '''\n",
    "    yclass= np.hstack((y_pred[0], y_pred[1],y_pred[2],y_pred[3]))\n",
    "        \n",
    "    y_class = np.array( yclass )\n",
    "    '''\n",
    "    Get the index corresponding to the max value of column\n",
    "    '''\n",
    "    idx = np.argmax(y_class, axis=-1)\n",
    "    y_class = np.zeros(y_class.shape )\n",
    "    '''\n",
    "    Convert the one hot position into class label\n",
    "    '''\n",
    "    y_class[ np.arange(y_class.shape[0]), idx] = 1\n",
    "    y_train_pred = np.argmax(y_class, axis=1)\n",
    "    return y_train_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [[] for i in range(num_attributes)]\n",
    "for i in range(num_attributes):\n",
    "    y_pred[i] = model[i].predict(X_test_all)\n",
    "y_pred_label = give_ovr_class_label_output(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Confusion Matrix and Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[155   2  51   0]\n",
      " [ 18 138  50   0]\n",
      " [ 38   3 166   0]\n",
      " [ 10   1  23  10]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test_all, \\\n",
    "                      y_pred_label)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 70.52631578947368\n"
     ]
    }
   ],
   "source": [
    "a = accuracy_score(y_pred_label,y_test_all)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Precison and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label precision recall\n",
      "    0     0.701  0.745\n",
      "    1     0.958  0.670\n",
      "    2     0.572  0.802\n",
      "    3     1.000  0.227\n"
     ]
    }
   ],
   "source": [
    "print(\"label precision recall\")\n",
    "for label in range(4):\n",
    "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
