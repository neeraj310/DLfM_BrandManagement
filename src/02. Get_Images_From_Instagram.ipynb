{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Retrieval From Instagram\n",
    "\n",
    "**Goal:** collect image data from instagram and then preprocess it, extract information (image files) from a user's Instagram profile\n",
    "\n",
    "**Constraints:** the user has no way of setting the image size (in KB), the resolution (1080x1080) of the images found on Instagram. The images are extracted from the Instagram page in raw form.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Websites: \n",
    "\n",
    "This notebook's code is based on the following tutorials: \n",
    "\n",
    "https://medium.com/@srujana.rao2/scraping-instagram-with-python-using-selenium-and-beautiful-soup-8b72c186a058\n",
    "\n",
    "https://edmundmartin.com/scraping-instagram-with-python/\n",
    "\n",
    "https://michaeljsanders.com/2017/05/12/scrapin-and-scrollin.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:** *Remember to respect user’s rights when you download copyrighted content. Do not use images/videos from Instagram for commercial intent.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import dependencies\n",
    "\n",
    "Install non-standard libraries: requests, BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import choice\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# to install\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build InstagramScraper class\n",
    "based on: https://edmundmartin.com/scraping-instagram-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching user agents is often a best practice when web scraping and can help you avoid detection. Should the caller of our class have provided their own list of user agents we take a random agent from the provided list.  Otherwise we will return our default user agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class called InstagramScraper: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url header for requests.get()\n",
    "headers={'User-Agent':  'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'\n",
    "         ,  'content-type': 'application/json'\n",
    "         , 'accept-encoding': 'gzip, deflate, br'\n",
    "         , 'cache-control': 'no-cache'\n",
    "         , 'accept' : '*/*'\n",
    "         , 'accept-language' : 'de-DE, de; q=0.9,en-US; q=0.8,en;q=0.7'\n",
    "         #, 'referer' : url\n",
    "         , 'connection' : 'keep-alive'\n",
    "         , 'cookie' : 'ig_cb=1; ig_did=DA66C494-9DFE-48F6-BA63-66F11DF8EC03; csrftoken=ukE8jYSjQxVs1YGPYddEkAXsN6WZ4Qmw; mid=XoChrAALAAG78Upva7Ld0TAzeTtm; rur=ASH; urlgen=\"{\\\"2a04:ee41:4:95:91f9:b9d4:8aab:41c\\\": 15796\\054 \\\"213.55.241.7\\\": 15796\\054 \\\"2a04:ee41:4:95:60ae:def3:2fd7:3633\\\": 15796}:1jIpww:PTjjrSzpjC6dWww8-AVOnfdQAFA\"'\n",
    "        }\n",
    "#_user_agents = [\n",
    " #   'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstagramScraper:\n",
    "\n",
    "    def __init__(self, user_agents=None, proxy=None):\n",
    "        self.user_agents = user_agents\n",
    "        self.proxy = proxy\n",
    "\n",
    "    def __random_agent(self):\n",
    "        if self.user_agents and isinstance(self.user_agents, list):\n",
    "            return choice(self.user_agents)\n",
    "        return choice(_user_agents)\n",
    "\n",
    "    def __request_url(self, url):\n",
    "        \"\"\"Our second helper method is simply a wrapper around requests. \n",
    "        We pass in a URL and try to make a request using the provided user agent and proxy. \n",
    "        If we are unable to make the request or Instagram responds with a non-200 status code we simply re-raise the error. \n",
    "        If everything goes fine, we return the page in questions HTML.\"\"\"\n",
    "        try:\n",
    "            #response = requests.get(url, headers={'User-Agent': self.__random_agent()}, proxies={'http': self.proxy,\n",
    "                                                                                                # 'https': self.proxy})\n",
    "            response = requests.get(url, headers=headers, proxies={'http': self.proxy, 'https': self.proxy})\n",
    "            response.raise_for_status()\n",
    "        except requests.HTTPError:\n",
    "            raise requests.HTTPError('Received non 200 status code from Instagram')\n",
    "        except requests.RequestException:\n",
    "            raise requests.RequestException\n",
    "        else:\n",
    "            return response.text\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_json_data(html):\n",
    "        \"\"\"Instagram serve’s all the of information regarding a user in the form of JavaScript object. \n",
    "        This means that we can extract all of a users profile information and their recent posts by just \n",
    "        making a HTML request to their profile page. We simply need to turn this JavaScript object into \n",
    "        JSON, which is very easy to do.\"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        body = soup.find('body')\n",
    "        script_tag = body.find('script')\n",
    "        raw_string = script_tag.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "        return json.loads(raw_string)\n",
    "\n",
    "    def profile_page_metrics(self, profile_url):\n",
    "        results = {}\n",
    "        try:\n",
    "            response = self.__request_url(profile_url)\n",
    "            json_data = self.extract_json_data(response)\n",
    "            metrics = json_data['entry_data']['ProfilePage'][0]['graphql']['user']\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        else:\n",
    "            for key, value in metrics.items():\n",
    "                #print('key:', key, '-value:', value)\n",
    "                if key != 'edge_owner_to_timeline_media':\n",
    "                    if value and isinstance(value, dict):\n",
    "                        value = value['count']\n",
    "                        results[key] = value\n",
    "                    elif value:\n",
    "                        results[key] = value\n",
    "        return results\n",
    "\n",
    "    #TODO\n",
    "    def hash_page_metrics(self, profile_url):\n",
    "        results = {}\n",
    "        try:\n",
    "            response = self.__request_url(profile_url)\n",
    "            json_data = self.extract_json_data(response)\n",
    "            metrics = json_data['entry_data']['TagPage'][0]['graphql']['hashtag']\n",
    "         \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        else:\n",
    "            for key, value in metrics.items():\n",
    "                #print('metrics:', metrics)\n",
    "                if key != 'edge_hashtag_to_media' and key != 'edge_hashtag_to_top_posts' and key != 'profile_pic_url':\n",
    "                    results[key] = value\n",
    "                    if value and isinstance(value, dict):\n",
    "                        try: \n",
    "                            value = value['count']            \n",
    "                            results[key] = value\n",
    "                        except: \n",
    "                            results[key] = value\n",
    "                        try: \n",
    "                            sigma = []\n",
    "                            for i in range(0,5): \n",
    "                                #print(i)\n",
    "                                value = value['edges'][i]['node']['name']  \n",
    "                                #print(i)\n",
    "                            sigma.append(value)\n",
    "                            print(len(value['edges']['node']))\n",
    "                            \n",
    "                            #results[key] = sigma\n",
    "                        except: \n",
    "                            results[key] = value \n",
    "                    elif value:\n",
    "                        results[key] = value\n",
    "        return results\n",
    "    \n",
    "    def profile_page_posts(self, profile_url):\n",
    "        results = []\n",
    "        try:\n",
    "            response = self.__request_url(profile_url)\n",
    "            json_data = self.extract_json_data(response)\n",
    "            metrics = json_data['entry_data']['ProfilePage'][0]['graphql']['user']['edge_owner_to_timeline_media'][\"edges\"]\n",
    "            #pprint(metrics)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        else:\n",
    "            for node in metrics:\n",
    "                node = node.get('node')\n",
    "                #if node and isinstance(node, dict): #this line only gets most recent post out\n",
    "                results.append(node)\n",
    "        return results\n",
    "    \n",
    "    def hashtag_page_posts(self, hashtag_url):\n",
    "        results = []\n",
    "        try:\n",
    "            response = self.__request_url(hashtag_url)\n",
    "            json_data = self.extract_json_data(response)\n",
    "            #pprint(json_data)\n",
    "            metrics = json_data['entry_data']['TagPage'][0]['graphql']['hashtag']['edge_hashtag_to_media'][\"edges\"]\n",
    "            #pprint(metrics)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        else:\n",
    "            for node in metrics:\n",
    "                node = node.get('node')\n",
    "                #if node and isinstance(node, dict): #this line only gets most recent post out\n",
    "                results.append(node)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load URLS of Brand Names Data\n",
    "\n",
    "Specify instragram USERNAME profile whose page you want to scrape. Get a dictionary with all information (image, comments, etc.) from that Instagram profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to specify\n",
    "directory= r'C:\\Users\\Anonym\\Documents\\GitHub\\DLfM_BrandManagement\\data\\instagram_urls'\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get out all apparel brands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abercrombie', 'adidas', 'anntaylor', 'bacardiusa', 'bananarepublic']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "data = pd.read_csv(\"firm_usernames.csv\", header=None)\n",
    "\n",
    "firm_usernames = data[0].tolist()\n",
    "firm_usernames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fanta', 'coorslight', 'greygoose', 'corona', 'monsterenergy']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"instagram_hashtags.csv\", header=None)\n",
    "\n",
    "instagram_hashtags = data[0].tolist()\n",
    "instagram_hashtags[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Specify Instagram page(s)\n",
    "\n",
    "Specify instragram USERNAME profile whose page you want to scrape. Get a dictionary with all information (image, comments, etc.) from that Instagram profile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-profile Page\n",
    "\n",
    "If you want to scrape a user-profile page, specify the username as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple firms  \n",
    "urls = []\n",
    "hashtag = False\n",
    "\n",
    "for username in firm_usernames: \n",
    "    url = 'https://www.instagram.com/'+username+'/?hl=en'\n",
    "    urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one firm only \n",
    "# to specify\n",
    "username='cailler_suisse'\n",
    "hashtag = False\n",
    "url = 'https://www.instagram.com/'+username+'/?hl=en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashtag Page\n",
    "\n",
    "If you want to open a hashtag page (instead of a user profile): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple brands  \n",
    "hash_urls = []\n",
    "username = False\n",
    "\n",
    "for hashtag in instagram_hashtags: \n",
    "    url = 'https://www.instagram.com/explore/tags/'+hashtag\n",
    "    hash_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one brand only \n",
    "\n",
    "# to specify\n",
    "hashtag='cailler'\n",
    "username = False\n",
    "url = 'https://www.instagram.com/explore/tags/'+hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get information from Instagram page(s) [optional]\n",
    "\n",
    "Now that the url of the Instagram page is defined, it will extract out all the posts or meta-information from the website usinge the InstagramScraper class. \n",
    "\n",
    "Get meta-information metrics by using a class method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'biography': '🌱plant-based recipes & wholesome living \\n'\n",
      "              '🍒nourish the cells & the soul \\n'\n",
      "              '🌱a YouTube community of 2M friends 👩🏻\\u200d🌾\\n'\n",
      "              '👇 NEW VIDEO 👇',\n",
      " 'business_category_name': 'Publishers',\n",
      " 'category_id': '2707',\n",
      " 'edge_felix_video_timeline': 0,\n",
      " 'edge_follow': 127,\n",
      " 'edge_followed_by': 531071,\n",
      " 'edge_media_collections': 0,\n",
      " 'edge_mutual_followed_by': 0,\n",
      " 'edge_saved_media': 0,\n",
      " 'external_url': 'https://youtu.be/0Kgi-H2W7Hk',\n",
      " 'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Fyoutu.be%2F0Kgi-H2W7Hk&e=ATM5rZNI8I5aBiZz3RAszJWMkhflagAU_QiH_SQDII3ITWclaigcQbJHAT__clKn0V1x15eE&s=1',\n",
      " 'full_name': 'Sadia Badiei, BSc Dietetics',\n",
      " 'highlight_reel_count': 1,\n",
      " 'id': '2072931271',\n",
      " 'is_business_account': True,\n",
      " 'is_verified': True,\n",
      " 'profile_pic_url': 'https://instagram.fzrh2-1.fna.fbcdn.net/v/t51.2885-19/s150x150/84057956_823380854858266_527460638654464000_n.jpg?_nc_ht=instagram.fzrh2-1.fna.fbcdn.net&_nc_ohc=RvJ85_MOJB4AX_BHBpW&oh=b186936487509345806919d712d1c3fd&oe=5EAC5272',\n",
      " 'profile_pic_url_hd': 'https://instagram.fzrh2-1.fna.fbcdn.net/v/t51.2885-19/s320x320/84057956_823380854858266_527460638654464000_n.jpg?_nc_ht=instagram.fzrh2-1.fna.fbcdn.net&_nc_ohc=RvJ85_MOJB4AX_BHBpW&oh=73434471df87cec9e259b96c706cca41&oe=5EA954FD',\n",
      " 'username': 'pickuplimes'}\n"
     ]
    }
   ],
   "source": [
    "# get profile page metrics\n",
    "from pprint import pprint\n",
    "\n",
    "k = InstagramScraper()\n",
    "results = k.profile_page_metrics(url) \n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hashtag page metrics\n",
    "from pprint import pprint\n",
    "\n",
    "k = InstagramScraper()\n",
    "#TODO\n",
    "results = k.hash_page_metrics(url) \n",
    "#pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get image posts from Instagram page(s)\n",
    "\n",
    "Get all posts on an Instagram **profile page** that are visible on the landing page (more items only load as you scroll downwards). The page loads 12 items at a time, and I need to scroll to load all entries (for a total of 120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pages that have access denial because of age limit\n",
    "# are you 18 or over? \n",
    "#urls.remove('https://www.instagram.com/bacardiusa/?hl=en')\n",
    "# are you 21 or over? \n",
    "#urls.remove('https://www.instagram.com/budlight/?hl=en')\n",
    "# are you 21 or over? \n",
    "#urls.remove('https://www.instagram.com/budweiser/?hl=en')\n",
    "# are you 18 or over? \n",
    "#urls.remove('https://www.instagram.com/coorslight/?hl=en')\n",
    "# are you 18 or over? \n",
    "#urls.remove('https://www.instagram.com/corona/?hl=en')\n",
    "# are you 18 or over? \n",
    "#urls.remove('https://www.instagram.com/greygoose/?hl=en')\n",
    "# are you 18 or over? \n",
    "#urls.remove('https://www.instagram.com/jackdaniels_us/?hl=en')\n",
    "# are you 18 or over? \n",
    "#urls.remove('https://www.instagram.com/korbel_1882/?hl=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items to be removed \n",
    "unwanted_num = {'bacardiusa', 'budlight', 'budweiser', 'coorslight', 'corona', 'greygoose', 'jackdaniels_us', 'korbel_1882'} \n",
    "  \n",
    "firm_usernames = [ele for ele in firm_usernames if ele not in unwanted_num] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instagram page:  https://www.instagram.com/abercrombie/?hl=en\n",
      "Instagram page:  https://www.instagram.com/adidas/?hl=en\n",
      "Instagram page:  https://www.instagram.com/anntaylor/?hl=en\n",
      "Instagram page:  https://www.instagram.com/bananarepublic/?hl=en\n",
      "Instagram page:  https://www.instagram.com/bigelowtea/?hl=en\n",
      "Instagram page:  https://www.instagram.com/carhartt/?hl=en\n",
      "Instagram page:  https://www.instagram.com/cocacola/?hl=en\n",
      "Instagram page:  https://www.instagram.com/converse/?hl=en\n",
      "Instagram page:  https://www.instagram.com/dockerskhakis/?hl=en\n",
      "Instagram page:  https://www.instagram.com/dolcegabbana/?hl=en\n",
      "Instagram page:  https://www.instagram.com/domperignon/?hl=en\n",
      "Instagram page:  https://www.instagram.com/drpepper/?hl=en\n",
      "Instagram page:  https://www.instagram.com/eddiebauer/?hl=en\n",
      "Instagram page:  https://www.instagram.com/fanta/?hl=en\n",
      "Instagram page:  https://www.instagram.com/gap/?hl=en\n",
      "Instagram page:  https://www.instagram.com/gatorade/?hl=en\n",
      "Instagram page:  https://www.instagram.com/gucci/?hl=en\n",
      "Instagram page:  https://www.instagram.com/guess/?hl=en\n",
      "Instagram page:  https://www.instagram.com/hanesbrasil/?hl=en\n",
      "Instagram page:  https://www.instagram.com/hollisterco/?hl=en\n",
      "Instagram page:  https://www.instagram.com/honesttea/?hl=en\n",
      "Instagram page:  https://www.instagram.com/jcrew/?hl=en\n",
      "Instagram page:  https://www.instagram.com/joeboxerlicky/?hl=en\n",
      "Instagram page:  https://www.instagram.com/juicycouture/?hl=en\n",
      "Instagram page:  https://www.instagram.com/kennethcole/?hl=en\n",
      "Instagram page:  https://www.instagram.com/levis/?hl=en\n",
      "Instagram page:  https://www.instagram.com/lipton/?hl=en\n",
      "Instagram page:  https://www.instagram.com/llbean/?hl=en\n",
      "Instagram page:  https://www.instagram.com/luckybrandme/?hl=en\n",
      "Instagram page:  https://www.instagram.com/moetchandon/?hl=en\n",
      "Instagram page:  https://www.instagram.com/monsterenergy/?hl=en\n",
      "Instagram page:  https://www.instagram.com/nesquikusa/?hl=en\n",
      "Instagram page:  https://www.instagram.com/oldnavy/?hl=en\n",
      "Instagram page:  https://www.instagram.com/oshkoshkids/?hl=en\n",
      "Instagram page:  https://www.instagram.com/prada/?hl=en\n",
      "Instagram page:  https://www.instagram.com/ralphlauren/?hl=en\n",
      "Instagram page:  https://www.instagram.com/sanpellegrino_official/?hl=en\n",
      "Instagram page:  https://www.instagram.com/snapple/?hl=en\n",
      "Instagram page:  https://www.instagram.com/tazo/?hl=en\n",
      "Instagram page:  https://www.instagram.com/tommyhilfiger/?hl=en\n",
      "Instagram page:  https://www.instagram.com/underarmour/?hl=en\n",
      "Instagram page:  https://www.instagram.com/urbanoutfitters/?hl=en\n",
      "Instagram page:  https://www.instagram.com/victoriassecret/?hl=en\n",
      "Instagram page:  https://www.instagram.com/vitaminwater/?hl=en\n",
      "Instagram page:  https://www.instagram.com/welchs/?hl=en\n",
      "Number of scanned Instagram profile pages:  45\n"
     ]
    }
   ],
   "source": [
    "# get posts (images) from multiple profile pages \n",
    "from pprint import pprint\n",
    "\n",
    "resultz = []\n",
    "for url in urls: \n",
    "    k = InstagramScraper()\n",
    "    results = k.profile_page_posts(url)\n",
    "    resultz.append(results)\n",
    "    print('Instagram page: ', url)\n",
    "\n",
    "print('Total number of Instagram pages: ', len(resultz))\n",
    "print('Total number of images: ', len(resultz)*len(resultz[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instagram page:  https://www.instagram.com/cailler_suisse/?hl=en\n",
      "Posts on Instagram profile page:  12\n",
      "Second image url on instagram profile:  https://instagram.fzrh2-1.fna.fbcdn.net/v/t51.2885-15/e35/89358555_897978820672238_2751193362800626603_n.jpg?_nc_ht=instagram.fzrh2-1.fna.fbcdn.net&_nc_cat=102&_nc_ohc=dwrtA5oeKbIAX9fhmV_&oh=2f411f9a116087d6449822aec11e3ae2&oe=5EAA50BB\n"
     ]
    }
   ],
   "source": [
    "# get posts (images) from single profile page \n",
    "from pprint import pprint\n",
    "\n",
    "k = InstagramScraper()\n",
    "results = k.profile_page_posts(url)\n",
    "\n",
    "print('Instagram page: ', url)\n",
    "print('Posts on Instagram profile page: ', len(results))\n",
    "print('Second image url on instagram profile: ', results[1]['display_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all posts on an Instagram **hashtag page** that are visible on the landing page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instagram page:  https://www.instagram.com/explore/tags/fanta\n",
      "Instagram page:  https://www.instagram.com/explore/tags/coorslight\n",
      "Instagram page:  https://www.instagram.com/explore/tags/greygoose\n",
      "Instagram page:  https://www.instagram.com/explore/tags/corona\n",
      "Instagram page:  https://www.instagram.com/explore/tags/monsterenergy\n",
      "Instagram page:  https://www.instagram.com/explore/tags/minutemaid\n",
      "Instagram page:  https://www.instagram.com/explore/tags/gatorade\n",
      "Instagram page:  https://www.instagram.com/explore/tags/jackdaniels\n",
      "Instagram page:  https://www.instagram.com/explore/tags/abercrombie\n",
      "Instagram page:  https://www.instagram.com/explore/tags/carhartt\n",
      "Instagram page:  https://www.instagram.com/explore/tags/eddiebauer\n",
      "Instagram page:  https://www.instagram.com/explore/tags/joeboxer\n",
      "Instagram page:  https://www.instagram.com/explore/tags/underarmour\n",
      "Instagram page:  https://www.instagram.com/explore/tags/adidas\n",
      "Instagram page:  https://www.instagram.com/explore/tags/cocacola\n",
      "Instagram page:  https://www.instagram.com/explore/tags/juicycouture\n",
      "Instagram page:  https://www.instagram.com/explore/tags/urbanoutfitters\n",
      "Instagram page:  https://www.instagram.com/explore/tags/anntaylor\n",
      "Instagram page:  https://www.instagram.com/explore/tags/converse\n",
      "Instagram page:  https://www.instagram.com/explore/tags/gap\n",
      "Instagram page:  https://www.instagram.com/explore/tags/kennethcole\n",
      "Instagram page:  https://www.instagram.com/explore/tags/oldnavy\n",
      "Instagram page:  https://www.instagram.com/explore/tags/victoriassecret\n",
      "Instagram page:  https://www.instagram.com/explore/tags/korbel\n",
      "Instagram page:  https://www.instagram.com/explore/tags/vitaminwater\n",
      "Instagram page:  https://www.instagram.com/explore/tags/bacardi\n",
      "Instagram page:  https://www.instagram.com/explore/tags/levis\n",
      "Instagram page:  https://www.instagram.com/explore/tags/prada\n",
      "Instagram page:  https://www.instagram.com/explore/tags/bananarepublic\n",
      "Instagram page:  https://www.instagram.com/explore/tags/dockers\n",
      "Instagram page:  https://www.instagram.com/explore/tags/guess\n",
      "Instagram page:  https://www.instagram.com/explore/tags/lipton\n",
      "Instagram page:  https://www.instagram.com/explore/tags/sanpellegrino\n",
      "Instagram page:  https://www.instagram.com/explore/tags/bigelow\n",
      "Instagram page:  https://www.instagram.com/explore/tags/dolcegabbana\n",
      "Instagram page:  https://www.instagram.com/explore/tags/hanes\n",
      "Instagram page:  https://www.instagram.com/explore/tags/luckybrand\n",
      "Instagram page:  https://www.instagram.com/explore/tags/snapple\n",
      "Instagram page:  https://www.instagram.com/explore/tags/budlight\n",
      "Instagram page:  https://www.instagram.com/explore/tags/domperignon\n",
      "Instagram page:  https://www.instagram.com/explore/tags/honesttea\n",
      "Instagram page:  https://www.instagram.com/explore/tags/budweiser\n",
      "Instagram page:  https://www.instagram.com/explore/tags/drpepper\n",
      "Instagram page:  https://www.instagram.com/explore/tags/moetchandon\n",
      "Instagram page:  https://www.instagram.com/explore/tags/tazo\n",
      "Instagram page:  https://www.instagram.com/explore/tags/llbean\n",
      "Instagram page:  https://www.instagram.com/explore/tags/oshkosh\n",
      "Instagram page:  https://www.instagram.com/explore/tags/ralphlauren\n",
      "Instagram page:  https://www.instagram.com/explore/tags/gucci\n",
      "Instagram page:  https://www.instagram.com/explore/tags/tommyhilfiger\n",
      "Instagram page:  https://www.instagram.com/explore/tags/hollister\n",
      "Instagram page:  https://www.instagram.com/explore/tags/jcrew\n",
      "Instagram page:  https://www.instagram.com/explore/tags/welchs\n",
      "Instagram page:  https://www.instagram.com/explore/tags/motts\n",
      "Instagram page:  https://www.instagram.com/explore/tags/nesquik\n",
      "Instagram page:  https://www.instagram.com/explore/tags/swissmiss\n",
      "Total number of Instagram hashtag pages:  56\n",
      "Total number of hashed images:  3976\n"
     ]
    }
   ],
   "source": [
    "# get posts (images) from multiple hashtag pages \n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "hash_result = []\n",
    "for url in hash_urls: \n",
    "    k = InstagramScraper()\n",
    "    results = k.hashtag_page_posts(url)\n",
    "    hash_result.append(results)\n",
    "    print('Instagram page: ', url)\n",
    "\n",
    "print('Total number of Instagram hashtag pages: ', len(hash_result))\n",
    "print('Total number of hashed images: ', len(hash_result)*len(hash_result[0]))\n",
    "print('Number of images per Instagram hashtag page: ', len(hash_result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instagram page:  https://www.instagram.com/explore/tags/cailler\n",
      "Posts on Instagram hashtag page:  72\n",
      "Second image url on instagram hashtag:  https://instagram.fzrh2-1.fna.fbcdn.net/v/t51.2885-15/e35/90321070_2337910599839314_269479700121283760_n.jpg?_nc_ht=instagram.fzrh2-1.fna.fbcdn.net&_nc_cat=110&_nc_ohc=k_47zRnnBLoAX_7BBam&oh=c5e68bb98175bf0db114b1d564988261&oe=5E847F50\n"
     ]
    }
   ],
   "source": [
    "# get posts (images) from a hashtag page \n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "k = InstagramScraper()\n",
    "results = k.hashtag_page_posts(url)\n",
    "\n",
    "#pprint(results)\n",
    "print('Instagram page: ', url)\n",
    "print('Posts on Instagram hashtag page: ', len(results))\n",
    "print('Second image url on instagram hashtag: ', results[1]['display_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save images from list of dict \n",
    "\n",
    "Use requests library to download images from the ‘display_url’ in pandas ‘result’ data frame and store them with respective shortcode as file name.\n",
    "\n",
    "Specify the directory for storing the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_usernames=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\\\Users\\\\Anonym\\\\Documents\\\\GitHub\\\\DLfM_BrandManagement\\\\data\\\\instagram_images\\\\abercrombie\\\\hashtag\\\\abercrombie'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-bbda9c48bd4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# set directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musername\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'hashtag'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\\\Users\\\\Anonym\\\\Documents\\\\GitHub\\\\DLfM_BrandManagement\\\\data\\\\instagram_images\\\\abercrombie\\\\hashtag\\\\abercrombie'"
     ]
    }
   ],
   "source": [
    "# download all visible images from multiple Instagram pages \n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# to specify\n",
    "directory= r\"C:\\Users\\Anonym\\Documents\\GitHub\\DLfM_BrandManagement\\data\"\n",
    "folder = 'instagram_images' #image root folder, all subfolders' name are firmnames\n",
    "\n",
    "os.chdir(directory)\n",
    "\n",
    "try: \n",
    "    os.mkdir(folder)\n",
    "except: \n",
    "    pass\n",
    "\n",
    "path = os.path.join(directory, folder)\n",
    "os.chdir(path)\n",
    "\n",
    "if firm_usernames: \n",
    "    for i, username in enumerate(firm_usernames): \n",
    "        try: \n",
    "            os.mkdir(os.path.join(path, username))\n",
    "        except: \n",
    "            pass\n",
    "        \n",
    "        # set directory \n",
    "        directory = os.path.join(path, username)\n",
    "        os.chdir(directory)   \n",
    "        folder = 'user_profile'\n",
    "        try: \n",
    "            os.mkdir(folder)\n",
    "        except: \n",
    "            pass\n",
    "        path = os.path.join(directory, folder)\n",
    "        os.chdir(path)\n",
    "        \n",
    "        # get image url \n",
    "        for j in range(len(resultz[i])): \n",
    "            r = requests.get(resultz[i][j]['display_url'], stream=True)\n",
    "            with open(resultz[i][j]['shortcode']+\".jpg\", 'wb') as f:\n",
    "                # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "                r.raw.decode_content = True\n",
    "                # Copy the response stream raw data to local image file.\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "                # Remove the image url response object.\n",
    "                del r\n",
    "\n",
    "#TODO\n",
    "elif instagram_hashtags: \n",
    "    for i, hashtag in enumerate(instagram_hashtags):\n",
    "        try: \n",
    "            os.mkdir(os.path.join(path, hashtag))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # set directory \n",
    "        directory = os.path.join(path, hashtag)\n",
    "        os.chdir(directory)   \n",
    "        folder = 'hashtag'\n",
    "        try: \n",
    "            os.mkdir(folder)\n",
    "        except: \n",
    "            pass\n",
    "        path = os.path.join(directory, folder)\n",
    "        os.chdir(path)\n",
    "        \n",
    "        # get image url \n",
    "        for j in range(len(hash_result[i])): \n",
    "            r = requests.get(hash_result[i][j]['display_url'], stream=True)\n",
    "            with open(hash_result[i][j]['shortcode']+\".jpg\", 'wb') as f:\n",
    "                # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "                r.raw.decode_content = True\n",
    "                # Copy the response stream raw data to local image file.\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "                # Remove the image url response object.\n",
    "                del r\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0e2af08abc04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'display_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shortcode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Set decode_content value to True, otherwise the downloaded image file's size will be zero.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Unexpected EOF'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1819\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1820\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1821\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1822\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# download all visible images from an Instagram page \n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# to specify\n",
    "directory= r\"C:\\Users\\Anonym\\Documents\\GitHub\\DLfM_BrandManagement\\data\"\n",
    "folder = 'instagram_images'\n",
    "\n",
    "path = os.path.join(directory, folder)\n",
    "\n",
    "try: \n",
    "    os.mkdir(folder)\n",
    "except: \n",
    "    pass\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "if username: \n",
    "    try: \n",
    "        os.mkdir(os.path.join(path, username))\n",
    "    except: \n",
    "        pass\n",
    "    os.chdir(os.path.join(path, username))\n",
    "elif hashtag: \n",
    "    try: \n",
    "        os.mkdir(os.path.join(path, hashtag))\n",
    "    except:\n",
    "        pass\n",
    "    os.chdir(os.path.join(path, hashtag))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    r = requests.get(results[i]['display_url'], stream=True)\n",
    "    with open(results[i]['shortcode']+\".jpg\", 'wb') as f:\n",
    "        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "        r.raw.decode_content = True\n",
    "        # Copy the response stream raw data to local image file.\n",
    "        shutil.copyfileobj(r.raw, f)\n",
    "        # Remove the image url response object.\n",
    "        del r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download one image only\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# to specify\n",
    "directory= r\"C:\\Users\\Anonym\\Documents\\GitHub\\DLfM_BrandManagement\\data\"\n",
    "os.chdir(directory)\n",
    "\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open(directory+\"B-Tckr0AgrH\"+\".jpg\", 'wb') as f:\n",
    "    # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "    r.raw.decode_content = True\n",
    "    # Copy the response stream raw data to local image file.\n",
    "    shutil.copyfileobj(r.raw, f)\n",
    "    # Remove the image url response object.\n",
    "    del r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
